<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Jitesh Jain</title>
    <link>https://praeclarumjj3.github.io/project/</link>
      <atom:link href="https://praeclarumjj3.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 10 Apr 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://praeclarumjj3.github.io/images/icon_hu4ad8c95e6c63df308e088b9efcfa89f3_55886_512x512_fill_lanczos_center_2.png</url>
      <title>Projects</title>
      <link>https://praeclarumjj3.github.io/project/</link>
    </image>
    
    <item>
      <title>OLIE</title>
      <link>https://praeclarumjj3.github.io/project/olie/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/olie/</guid>
      <description>&lt;p&gt;OLIE was aimed to reconstruct the original image with the objects removed (editing) by incorporating the mask features as input to the reconstructor.&lt;/p&gt;
&lt;p&gt;After performing many experiments, we scrapped the idea. However, some of the experiments that I performed were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Using a Perturbator Model:&lt;/strong&gt; Taking inspiration from 
&lt;a href=&#34;https://ganpaint.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GanPaint&lt;/a&gt;, I tried editing images using perturbations in the reconstructor, however it didn&amp;rsquo;t work well.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Using Gated Convolutions:&lt;/strong&gt; Taking inspiration from 
&lt;a href=&#34;https://paperswithcode.com/paper/free-form-image-inpainting-with-gated&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Free-Form Image Inpainting with Gated Convolution&lt;/a&gt;, I used &lt;code&gt;Gated Modules&lt;/code&gt; instead of standard modules which gave even &lt;strong&gt;poorer results&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Using Two Stage Model:&lt;/strong&gt; Getting hole images from the reconstructor and then passing that into an inpainting model gave somewhat good results as the generating the hole image could be learned accurately to an extent, however, the results were no better than the common inpainting ones.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our aim was to come up with a &lt;strong&gt;Single Stage Model&lt;/strong&gt; for image editing using instance maps.&lt;/p&gt;
&lt;p&gt;For more info, please see the Code on &lt;code&gt;GitHub&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BackBone Profile</title>
      <link>https://praeclarumjj3.github.io/project/backbone/</link>
      <pubDate>Mon, 28 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/backbone/</guid>
      <description>&lt;p&gt;I performed experiments on various backbone networks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ResNet-18/34/50/101&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MobileNetv2&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Xception Net&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All the experiments were performed on a single &lt;strong&gt;RTX 2080Ti GPU&lt;/strong&gt;, a single &lt;strong&gt;TitanXP GPU&lt;/strong&gt; and a single &lt;strong&gt;CPU&lt;/strong&gt; &lt;em&gt;indivdually&lt;/em&gt;. For each model architecture, I collected the stats including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Execution Time&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Memory Used&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Number of Parameters&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Paper Summaries</title>
      <link>https://praeclarumjj3.github.io/project/summary_of_papers/</link>
      <pubDate>Tue, 07 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/summary_of_papers/</guid>
      <description>&lt;p&gt;Summaries:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/You_only_train_once.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;You Only Train Once : Loss-conditional training of deep networks, ICLR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/GrokNet.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GrokNet: Unified Computer Vision Model Trunk and Embeddings For Commerce, KDD 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Semantically_multi-modal_image_synthesis.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Semantically multi-modal image synthesis, CVPR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/GameGAN.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learning to Simulate Dynamic Environments with GameGAN, CVPR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Adversarial_RL.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adversarial Policies : Attacking deep reinforcement learning, ICLR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Unsupervised_learning_for_3D_objects_from_images.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild, CVPR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/BYOL.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning, CVPR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ChatBot with Pytorch</title>
      <link>https://praeclarumjj3.github.io/project/chatbot/</link>
      <pubDate>Fri, 19 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/chatbot/</guid>
      <description>&lt;p&gt;I implemented a chatbot in Pytorch on the Cornell Movie Dialog Corpus dataset using GRUs and Attention mechanism.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>VQ-VAE on MNIST</title>
      <link>https://praeclarumjj3.github.io/project/vq_vae/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/vq_vae/</guid>
      <description>&lt;p&gt;I tried to implement 
&lt;a href=&#34;https://arxiv.org/abs/1711.00937&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VQ-VAE&lt;/a&gt; in Pytorch on the MNIST dataset.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
