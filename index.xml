<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jitesh Jain</title>
    <link>https://praeclarumjj3.github.io/</link>
      <atom:link href="https://praeclarumjj3.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Jitesh Jain</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://praeclarumjj3.github.io/media/icon_hud166e63c6d63b20b4040daaa47de5209_74785_512x512_fill_lanczos_center_3.png</url>
      <title>Jitesh Jain</title>
      <link>https://praeclarumjj3.github.io/</link>
    </image>
    
    <item>
      <title>Example Talk</title>
      <link>https://praeclarumjj3.github.io/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Summer Diaries: Intern Diary of an Undergrad DL Researcher</title>
      <link>https://praeclarumjj3.github.io/post/summer_diary_wo/</link>
      <pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/post/summer_diary_wo/</guid>
      <description>&lt;p&gt;This summer, I worked as a remote research intern at SHI Lab @ University of Oregon (UO) and Picsart AI Research (PAIR). I joined the SHI Lab to work with Professor Humphrey Shi in November 2020 during my second year and continued my work there during the summers, and I joined PAIR during the summers (June 2021). My research focused on the field of Computer Vision during both my internships.&lt;/p&gt;
&lt;p&gt;Read more about my intern experience at: &lt;a href=&#34;http://watchout.iitr.ac.in/2022/01/summer-diaries-jitesh-jain&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://watchout.iitr.ac.in/2022/01/summer-diaries-jitesh-jain&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SeMask: Semantically Masked Transformers for Semantic Segmentation</title>
      <link>https://praeclarumjj3.github.io/publication/semask/</link>
      <pubDate>Thu, 23 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/publication/semask/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Contemporary Overthinking Problem</title>
      <link>https://praeclarumjj3.github.io/post/overthinking/</link>
      <pubDate>Fri, 26 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/post/overthinking/</guid>
      <description>&lt;p&gt;Since the onset of the COVID-19 pandemic, the following lockdowns and stay &amp;amp; work from home situations, the concept of Overthinking has gained popularity. Moreover, now and then, I find the gen-z people (and even me sometimes) replying to ‚ÄúWhat you doing?‚Äù texts with ‚ÄúOverthinking.‚Äù Surprisingly, I have seen people setting their social profiles‚Äô status as Overthinking. It made me wonder if we have started treating overthinking as a clich√©d concept that might overshadow the problems that the actual overthinking state brings.&lt;/p&gt;
&lt;p&gt;This article will explain my opinion about overthinking and why it is becoming more clich√© than a serious problem.&lt;/p&gt;
&lt;p&gt;Read more at: &lt;a href=&#34;https://jitesh-j.medium.com/the-contemporary-overthinking-problem-fce4c385dfb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://jitesh-j.medium.com/the-contemporary-overthinking-problem-fce4c385dfb&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Riding the Noisy Research Track</title>
      <link>https://praeclarumjj3.github.io/post/research_ride/</link>
      <pubDate>Wed, 28 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/post/research_ride/</guid>
      <description>&lt;p&gt;Alright, people! This article will share my experience and learnings during the last eight months as an undergrad researcher. For those reading one of my blogs for the first time, I am a CSE undergrad (about to enter 3rd year) and am working as a Research Intern at &lt;em&gt;&lt;a href=&#34;https://www.humphreyshi.com/people&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SHI Lab @ UO&lt;/a&gt;&lt;/em&gt; and &lt;em&gt;&lt;a href=&#34;https://picsart.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Picsart&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Now, before we dive in, let me clear it out that I have probably had a more intense research experience for better or worse than some of the other undergrad people at IITR. So, don‚Äôt make any judgments about research based on the content in this post üòõ. So, we got that sorted out. Let‚Äôs begin!&lt;/p&gt;
&lt;p&gt;Read more at: &lt;a href=&#34;https://jitesh-j.medium.com/riding-the-noisy-research-track-4035e64e7ea8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://jitesh-j.medium.com/riding-the-noisy-research-track-4035e64e7ea8&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AOT-GAN Experiments</title>
      <link>https://praeclarumjj3.github.io/project/aot-gan-experiments/</link>
      <pubDate>Wed, 19 May 2021 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/aot-gan-experiments/</guid>
      <description>&lt;p&gt;I conducted various experiments with &lt;strong&gt;AOT-GAN&lt;/strong&gt; proposed in the paper: &lt;a href=&#34;https://arxiv.org/abs/2104.01431&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aggregated Contextual Transformations for High-Resolution Image Inpainting&lt;/a&gt;) on the &lt;a href=&#34;http://places2.csail.mit.edu/download.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Places2&lt;/a&gt; dataset using the &lt;a href=&#34;https://nv-adlr.github.io/publication/partialconv-inpainting&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PConv Free Form Masks for Inpainting&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In particular, I focused on finding the effectivity of different losses while training the framework. I made several observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;adversarial loss&lt;/strong&gt; doesn&amp;rsquo;t seem to be contributing to the learning of the model as it stays almost the same throughout the training.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Training for longer than &lt;code&gt;1e4&lt;/code&gt; iterations doesn&amp;rsquo;t add much improvement to the results.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Training &lt;strong&gt;without style loss&lt;/strong&gt; produces blurry results. Therefore, style loss is an important component for texture related synthesis of images.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Training &lt;strong&gt;without adversarial loss&lt;/strong&gt; also produces good quality results!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more info, please see the Code on &lt;code&gt;GitHub&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Do self-help books really help?</title>
      <link>https://praeclarumjj3.github.io/post/self_help_books/</link>
      <pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/post/self_help_books/</guid>
      <description>&lt;p&gt;Alright, so this is going to be quite a short entry. A few days back, a friend of mine and I were talking about books. We were discussing the books that we have read. Well, she‚Äôs smart, so she was listing out great books like 1984, A Man Called Ove, etc. I told her how I had read quite a few of the ‚Äúself-help‚Äù books during the last year or so (well, pandemic time, so needed some motivation, I guess :3). Then she asked me:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Do self-help books really help?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Read more at: &lt;a href=&#34;https://jitesh-j.medium.com/do-self-help-books-really-help-8947e1393bd4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://jitesh-j.medium.com/do-self-help-books-really-help-8947e1393bd4&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OLIE</title>
      <link>https://praeclarumjj3.github.io/project/olie/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/olie/</guid>
      <description>&lt;p&gt;OLIE was aimed to reconstruct the original image with the objects removed (editing) by incorporating the mask features as input to the reconstructor.&lt;/p&gt;
&lt;p&gt;After performing many experiments, we scrapped the idea. However, some of the experiments that I performed were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Using a Perturbator Model:&lt;/strong&gt; Taking inspiration from &lt;a href=&#34;https://ganpaint.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GanPaint&lt;/a&gt;, I tried editing images using perturbations in the reconstructor, however it didn&amp;rsquo;t work well.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Using Gated Convolutions:&lt;/strong&gt; Taking inspiration from &lt;a href=&#34;https://paperswithcode.com/paper/free-form-image-inpainting-with-gated&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Free-Form Image Inpainting with Gated Convolution&lt;/a&gt;, I used &lt;code&gt;Gated Modules&lt;/code&gt; instead of standard modules which gave even &lt;strong&gt;poorer results&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Using Two Stage Model:&lt;/strong&gt; Getting hole images from the reconstructor and then passing that into an inpainting model gave somewhat good results as the generating the hole image could be learned accurately to an extent, however, the results were no better than the common inpainting ones.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our aim was to come up with a &lt;strong&gt;Single Stage Model&lt;/strong&gt; for image editing using instance maps.&lt;/p&gt;
&lt;p&gt;For more info, please see the Code on &lt;code&gt;GitHub&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>granim</title>
      <link>https://praeclarumjj3.github.io/project/granim/</link>
      <pubDate>Sat, 03 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/granim/</guid>
      <description>&lt;p&gt;&lt;strong&gt;granim&lt;/strong&gt; makes it easier to plot animated graphs using the Manim-Engine. This project is still under development. Contributors are always welcome!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Priority Hierarchy Dilemma</title>
      <link>https://praeclarumjj3.github.io/post/priority/</link>
      <pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/post/priority/</guid>
      <description>&lt;p&gt;Right, so this isn&amp;rsquo;t a well-planned blog. I just wanted to write something up, and this idea popped into my head while guessing the mid-term&amp;rsquo;s syllabus with one of my friends. It got me wondering about the importance that I give to these college exams is even lesser than writing a random blog even when my exams are less than a week away xD.&lt;/p&gt;
&lt;p&gt;Read more at: &lt;a href=&#34;https://jitesh-j.medium.com/the-priority-hierarchy-dilemma-91b39cb397f&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://jitesh-j.medium.com/the-priority-hierarchy-dilemma-91b39cb397f&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why Research if I can Develop?!</title>
      <link>https://praeclarumjj3.github.io/post/why_research/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/post/why_research/</guid>
      <description>&lt;p&gt;Hello there! Alright, so it has been more than 3 months since my last blog, where I described how a CSE student‚Äôs life at IITR is being turned into a living hell by the system and professors. Sadly, the going has only got more challenging, with profs imposing more of their ingenious will on students. I recently had my ETEs, so I am brimming with academic frustration and will probably end up writing another blog, but that‚Äôs a topic for another day :P&lt;/p&gt;
&lt;p&gt;Read more at: &lt;a href=&#34;https://jitesh-j.medium.com/why-research-if-i-can-develop-c90bd3ce3540&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://jitesh-j.medium.com/why-research-if-i-can-develop-c90bd3ce3540&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BackBone Profile</title>
      <link>https://praeclarumjj3.github.io/project/backbone/</link>
      <pubDate>Mon, 28 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/backbone/</guid>
      <description>&lt;p&gt;I performed experiments on various backbone networks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ResNet-18/34/50/101&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MobileNetv2&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Xception Net&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All the experiments were performed on a single &lt;strong&gt;RTX 2080Ti GPU&lt;/strong&gt;, a single &lt;strong&gt;TitanXP GPU&lt;/strong&gt; and a single &lt;strong&gt;CPU&lt;/strong&gt; &lt;em&gt;indivdually&lt;/em&gt;. For each model architecture, I collected the stats including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Execution Time&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Memory Used&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Number of Parameters&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ArxivApp</title>
      <link>https://praeclarumjj3.github.io/project/arxiv_app/</link>
      <pubDate>Thu, 26 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/arxiv_app/</guid>
      <description>&lt;p&gt;&lt;strong&gt;ArxivApp&lt;/strong&gt; lets you read, bookmark and download papers from arXiv.org. It also has a forum screen that lets you read and create notes/blogs about the different research papers you read!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>IITR ChatBot</title>
      <link>https://praeclarumjj3.github.io/project/iitr_bot/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/iitr_bot/</guid>
      <description>&lt;p&gt;We developed an assistance bot for the &lt;a href=&#34;https://www.iitr.ac.in/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IITR website&lt;/a&gt; using the &lt;a href=&#34;https://rasa.com/docs/rasa/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RASA&lt;/a&gt; framework.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DEAP Cache: Deep Eviction Admission and Prefetching for Cache</title>
      <link>https://praeclarumjj3.github.io/publication/deap/</link>
      <pubDate>Sat, 19 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/publication/deap/</guid>
      <description></description>
    </item>
    
    <item>
      <title>IITR Security App</title>
      <link>https://praeclarumjj3.github.io/project/security_app/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/security_app/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;IITR Security App was developed to eliminate the use of paper by the guards to record the details of the visitors at IIT Roorkee.&lt;/li&gt;
&lt;li&gt;I worked on developing Front-End part of the app using Flutter.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Playstore Link&lt;/strong&gt;: &lt;a href=&#34;https://play.google.com/store/apps/details?id=in.ac.iitr.mdg.securityapp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://play.google.com/store/apps/details?id=in.ac.iitr.mdg.securityapp&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>One Year of Traversing the ‚ÄúeÀ£‚Äù Graph</title>
      <link>https://praeclarumjj3.github.io/post/one_year_at_iitr/</link>
      <pubDate>Sun, 02 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/post/one_year_at_iitr/</guid>
      <description>&lt;p&gt;Hey! So you must be wondering, ‚ÄúWhat the hell is e À£ doing in the title? It must be a scientific article!‚Äù Well, to put your mind at ease, this is not an article about the hidden beauty of e À£ (although that would be an excellent one :P). Instead, it is about a now sophomore‚Äôs year of life at IITR. Please allow me to take you to a flashback journey through time!&lt;/p&gt;
&lt;p&gt;Read more at: &lt;a href=&#34;https://medium.com/@jitesh_j/one-year-of-traversing-the-e-%CB%A3-graph-767973e9bf17?sk=8ea14ee7d09bebde5f02d73049b9ab96&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://medium.com/@jitesh_j/one-year-of-traversing-the-e-%CB%A3-graph-767973e9bf17?sk=8ea14ee7d09bebde5f02d73049b9ab96&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper Summaries</title>
      <link>https://praeclarumjj3.github.io/project/summary_of_papers/</link>
      <pubDate>Tue, 07 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/summary_of_papers/</guid>
      <description>&lt;p&gt;Summaries:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/You_only_train_once.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;You Only Train Once : Loss-conditional training of deep networks, ICLR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/GrokNet.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GrokNet: Unified Computer Vision Model Trunk and Embeddings For Commerce, KDD 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Semantically_multi-modal_image_synthesis.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Semantically multi-modal image synthesis, CVPR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/GameGAN.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learning to Simulate Dynamic Environments with GameGAN, CVPR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Adversarial_RL.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adversarial Policies : Attacking deep reinforcement learning, ICLR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Unsupervised_learning_for_3D_objects_from_images.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild, CVPR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/vlgiitr/papers_we_read/blob/master/summaries/BYOL.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning, CVPR 2020&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ChatBot with Pytorch</title>
      <link>https://praeclarumjj3.github.io/project/chatbot/</link>
      <pubDate>Fri, 19 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/chatbot/</guid>
      <description>&lt;p&gt;I implemented a chatbot in Pytorch on the Cornell Movie Dialog Corpus dataset using GRUs and Attention mechanism.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Curse of Dimensionality</title>
      <link>https://praeclarumjj3.github.io/post/curse_dimension/</link>
      <pubDate>Thu, 11 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/post/curse_dimension/</guid>
      <description>&lt;p&gt;Have you ever found yourself stuck in the middle of a problem having a large number of dimensions? You keep on trying harder and harder to come up with a solution that would satisfy all the dimensions of the problem. Still, every time one or another dimension makes ur efforts look futile! It turns out that you can solve a problem very efficiently when presented with not more than 2 or 3 dimensions. Nevertheless, this world is not kind to us every time! You might find yourself struggling amidst a problem, thinking&amp;hellip;&lt;/p&gt;
&lt;p&gt;Read more at: &lt;a href=&#34;https://medium.com/vlgiitr/the-curse-of-dimensionality-15f950e519d2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://medium.com/vlgiitr/the-curse-of-dimensionality-15f950e519d2&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>VQ-VAE on MNIST</title>
      <link>https://praeclarumjj3.github.io/project/vq_vae/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/vq_vae/</guid>
      <description>&lt;p&gt;I tried to implement &lt;a href=&#34;https://arxiv.org/abs/1711.00937&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VQ-VAE&lt;/a&gt; in Pytorch on the MNIST dataset.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Time Tracer</title>
      <link>https://praeclarumjj3.github.io/project/time_trace/</link>
      <pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/time_trace/</guid>
      <description>&lt;p&gt;A Flutter application developed as a self-learning project to help people keep track of their time expenditure.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Societyfy</title>
      <link>https://praeclarumjj3.github.io/project/societyfy/</link>
      <pubDate>Wed, 08 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/societyfy/</guid>
      <description>&lt;p&gt;SOCIETYFY is an app showcase app developed during MDG‚Äôs SoC event in December, 2019. Societyfy lets you discover new people based on your interest at any moment of time and make new bonds with people you share an interest with at any point in time through its specific chatrooms for each category.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PlayStore Link&lt;/strong&gt;: &lt;a href=&#34;https://play.google.com/store/apps/details?id=in.ac.mdg.iitr.societyfy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://play.google.com/store/apps/details?id=in.ac.mdg.iitr.societyfy&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Medium Blog&lt;/strong&gt;: &lt;a href=&#34;https://medium.com/mobile-development-group/societyfy-an-app-made-for-finding-company-at-anytime-for-anything-842e18151551&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt; Societyfy: An app made for finding company at any time for anything&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Geofile</title>
      <link>https://praeclarumjj3.github.io/project/geofile/</link>
      <pubDate>Sun, 05 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/project/geofile/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Geofile lets you couple files them with a specific location.&lt;/li&gt;
&lt;li&gt;I worked on developing Front-End part of the app using Flutter.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Playstore Early Access&lt;/strong&gt;: You can test the beta version on the Playstore by searching for &lt;strong&gt;geofile&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Societyfy, An app made for finding company at anytime for anything</title>
      <link>https://praeclarumjj3.github.io/post/societyfy/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/post/societyfy/</guid>
      <description>&lt;p&gt;Imagine a situation where you are at a place where you don‚Äôt know many people and feel a bit left out. You feel hesitant to go out for lunch or hangout or even go to a movie alone. This is where the concept of Societyfy comes in to rescue you.&lt;/p&gt;
&lt;p&gt;Read more at: &lt;a href=&#34;https://medium.com/mobile-development-group/societyfy-an-app-made-for-finding-company-at-anytime-for-anything-842e18151551&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://medium.com/mobile-development-group/societyfy-an-app-made-for-finding-company-at-anytime-for-anything-842e18151551&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://praeclarumjj3.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://praeclarumjj3.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
